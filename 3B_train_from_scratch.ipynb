{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oX3TnytELS5H"
   },
   "source": [
    "# Deep Learning Models\n",
    "\n",
    "### Trained from scratch:\n",
    "1. Deep network formed from **Dense Layers**. For this Neural Net, we will perform simple tokenization of our data and feed it to the Dense layers and calculate loss using the output and the one-hot encoding of the actual true value.\n",
    "\n",
    "2. **Deep Recurrent network**: We will tokenize our data and send it to our model consisting of Embedding layer followed by LSTM layer and adding dense layer to perform the classification.\n",
    "\n",
    "### Pre-Trained Models:\n",
    "1. Text Embedding GNews Swivel: This is a pre-trained model by Google which performs embedding of our input data. We follow this embedding with dense layers of our own to perform classification.\n",
    "\n",
    "2. **BERT**: This is Google's latest state-of-the-art language model made to perform multiple NLP tasks. Because BERT is an extremely heavy model, we will instead use Distilbert- A much lighter model preserving most of the accuracy of BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKDbD0r4nUdO"
   },
   "source": [
    "## Trained from scratch\n",
    "\n",
    "In this notebook, we will perform the classifications by training our own models from scratch. We will begin with the **Deep Feedforward** network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2Uh3RLMaqSH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmKQdIiEa6bd"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/My Drive/dataset_final.csv', engine='python')\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "sr = pd.isnull(df['title'])\n",
    "sr.loc[sr==True]\n",
    "df.drop(83369, axis=0, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "sr = pd.isnull(df['full_text'])\n",
    "drop_arr = sr.loc[sr==True].index.tolist()\n",
    "df.drop(drop_arr, axis=0, inplace=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7PVL1vzbPg7"
   },
   "outputs": [],
   "source": [
    "target_flairs = df['flair'].index.tolist()\n",
    "X_text = list(df['full_text'])\n",
    "Y = list(df['flair'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_text, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaBtDoDL_iRn"
   },
   "source": [
    "We will try to overcome the problem of the imbalance in our dataset by oversampling the data that we have less of. There are multiple methods we can use for this such as random over sampling, SMOTE and ADASYN. The best performing one for our data is SMOTE and we will oversample the flairs with lesser data points as given in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "b1i7CThObZe5",
    "outputId": "e7a316fd-a9cb-4113-ca16-78d49e4f25d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english',ngram_range=(1,1))\n",
    "\n",
    "x_train_tokenized = vect.fit_transform(x_train)\n",
    "x_test_tokenized = vect.transform(x_test)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy={'Coronavirus':6000, 'Science/Technology':6000,\n",
    "'Business/Finance':6000,\n",
    "'[R]eddiquette':6000,\n",
    "'Sports':6000,\n",
    "'Photography':6000})\n",
    "x_train_tokenized, y_train = smote.fit_resample(x_train_tokenized, y_train)\n",
    "\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train_bin = encoder.transform(y_train)\n",
    "y_test_bin = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "BfOIp2E_gU7Q",
    "outputId": "8254139c-0416-4a4e-d569-3b23e2bf598f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               32223744  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 32,290,698\n",
      "Trainable params: 32,290,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(x_train_tokenized.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6lfuRQpi9ym"
   },
   "outputs": [],
   "source": [
    "x_train_tokenized.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "4O63WIhQhSpy",
    "outputId": "7abccfae-11ef-4cfb-aed3-4e36b1195ada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "772/772 [==============================] - 84s 109ms/step - loss: 1.2094 - accuracy: 0.5844\n",
      "Epoch 2/4\n",
      "772/772 [==============================] - 82s 107ms/step - loss: 0.6539 - accuracy: 0.7784\n",
      "Epoch 3/4\n",
      "772/772 [==============================] - 82s 107ms/step - loss: 0.4266 - accuracy: 0.8572\n",
      "Epoch 4/4\n",
      "772/772 [==============================] - 83s 107ms/step - loss: 0.2856 - accuracy: 0.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbb7833e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "batch_size = 128\n",
    "model.fit(x_train_tokenized, y_train_bin,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "NGAV8aS_iv-i",
    "outputId": "6c8c70f3-d3e7-4281-97dd-18d4cbb892cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 - 1s - loss: 1.7118 - accuracy: 0.5759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7118370532989502, 0.5759423971176147]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tokenized.sort_indices()\n",
    "model.evaluate(x_test_tokenized,  y_test_bin, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAmbsRrVJaUY"
   },
   "source": [
    "We will now train an LSTM model to factor in the sequence and time-modelling and see if it increases the accuracy. The final model trained here does not use oversampling as it produces worse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qt7qGdDj3y_I"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_text, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TMEtKysn17vP",
    "outputId": "f59e20d2-895a-45b0-842d-1083197a0904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76131 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 100000\n",
    "maxlen = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "izBeMQc517mb",
    "outputId": "c7912aae-9e48-4e8f-e4a3-1fea67b85329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (74215, 500)\n"
     ]
    }
   ],
   "source": [
    "x_train_tokenized = tokenizer.texts_to_sequences(x_train)\n",
    "x_train_tokenized = pad_sequences(x_train_tokenized, maxlen=maxlen)\n",
    "x_test_tokenized = tokenizer.texts_to_sequences(x_test)\n",
    "x_test_tokenized = pad_sequences(x_test_tokenized, maxlen=maxlen)\n",
    "print('Shape of data tensor:', x_train_tokenized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N6lSbOKu17j8",
    "outputId": "c0bd7d88-0f28-4ff6-9130-ea5348adc7b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74215, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train_bin = encoder.transform(y_train)\n",
    "y_test_bin = encoder.transform(y_test)\n",
    "y_train_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "4Ktfco9n17eD",
    "outputId": "1dda320c-433f-429e-f77b-eef2cb9e0a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 100)          10000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 500, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 10,081,410\n",
      "Trainable params: 10,081,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=x_train_tokenized.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "BF5-Y4re17Sm",
    "outputId": "5cfb72ce-d892-406c-d34a-033a2135f2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "580/580 [==============================] - 1248s 2s/step - loss: 1.4090 - accuracy: 0.5170\n",
      "Epoch 2/3\n",
      "580/580 [==============================] - 1244s 2s/step - loss: 1.0225 - accuracy: 0.6569\n",
      "Epoch 3/3\n",
      "580/580 [==============================] - 1251s 2s/step - loss: 0.8219 - accuracy: 0.7239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbbb7e1d588>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "model.fit(x_train_tokenized, y_train_bin,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "MQu98sxqIkCf",
    "outputId": "68cfeecd-17e2-40b1-9685-f62d783d40fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994/994 - 111s - loss: 1.1561 - accuracy: 0.6181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1561249494552612, 0.6181343793869019]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_tokenized,  y_test_bin, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRgPvUTlJ1z0"
   },
   "source": [
    "Great! The time modelling did improve the accuracy by almost 4% from it's purely Dense model counterpart. This is in accordance with what you would expect as in the dense model, we are losing out on the information that is stored in the order of words in a post"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "3A train_from_scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
